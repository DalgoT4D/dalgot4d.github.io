# Data Analysis using LLMs

## v0 

`POST` `api/warehouse/ask/`

`POST` `api/warehouse/ask/{new_session_id}/save/`

`POST` `api/warehouse/ask/{session_id}/feedback/`

`GET` `api/warehouse/ask/sessions`

`GET` `api/warehouse/sync_tables`

## v1 (March 2025)

`POST` `api/warehouse/v1/ask/`

This endpoint takes a natural language `user_prompt` and generates a SQL query which (might) answer it. The SQL is generated by Vanna.

The org's warehouse needs to already have been used to train Vanna's RAG for this org.

Since this process can be time-consuming, the request handler offloads it to Celery. 

Celery task: `generate_sql_from_prompt_asked_on_warehouse` 

This task creates an `LlmSession` object of type `LONG_TEXT_SUMMARIZATION` in the database. The following data is saved into this session object:
- `Org`
- `OrgUser` who made the HTTP request
- a unique `session_id`
- the request id

The task then calls `warehousefunctions.generate_sql_from_warehouse_rag` to fetch the SQL.

`generate_sql_from_warehouse_rag` does the following:
1. Checks that the `org` has already been set up for this feature, by ensuring the existence of `Org.pgvector_creds` which is a lookup id in the secrets manager
2. Fetches the credentials from the secrets manager
3. Checks that the RAG is trained (the LLM service exposes `/api/vanna/train/check` to do this check)
4. Ask the LLM service to generate the SQL query. This is done by hitting `/api/vanna/ask` at the LLM service's end

For the LLM service to generate this SQL query, it needs both credentials to the warehouse as well as to the RAG database which Vanna uses


`POST` `api/warehouse/v1/ask/{session_id}/summarize/`

`POST` `api/warehouse/v1/ask/{session_id}/save/`

`POST` `api/warehouse/rag/train/`

`POST` `api/warehouse/table_data/run_sql/`

`POST` `api/warehouse/row_count/sql/`
