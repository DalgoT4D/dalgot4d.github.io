# Log summarization

Dalgo is able to summarization the logs generated by certain processes; this document explains how this is done and which generalizations can be made.

### LLM Service

The service https://github.com/DalgoT4D/ai-llm-service runs outside of Dalgo and exposes the following functionality:

1. Upload a file
2. Run queries against the file using LLM prompts
3. Delete the file and close the session

Dalgo summarizes logs from Prefect and Airbyte by 

1. Downloading them from Prefect / Airbyte
2. Uploading to the LLM service
3. Running fixed queries to fetch summaries


Since these are all time-consuming operations, they are run by Celery outside of django's http request-response loop

Airbyte logs are summarized by `ddpui/celeryworkers/tasks.py:summarize_airbyte_logs`

Prefect logs are summarized by `ddpui/celeryworkers/tasks.py:summarize_deployment_flow_run_logs`


Both of these Celery tasks follow the same pattern

1. Fetch the respective logs
   
2. Upload using `ddpui/core/llm_service.py:upload_text_as_file`

3. Query is using `ddpui/core/llm_service.py:file_search_query_and_poll`

4. Close the session `ddpui/core/llm_service.py:close_file_search_session`


### The `LlmSession` table

Summaries are tracked in a table called `LlmSession` which has the following columns

- `session_id`
- `Org`
- `OrgUser`
- `flow_run_id`
- `airbyte_job_id`
- `assistant_prompt`
- `user_prompts`
- `response`
- `response_meta`

When a summarization request comes in we use the `flow_run_id` / `airbyte_job_id` to see if a summary already exists; if so we return it without making another invocation to the LLM service. The requestor has the ability to demand a refresh though

